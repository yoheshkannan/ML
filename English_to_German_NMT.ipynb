{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English to German NMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/oZbsa8rcKIG7LmhpBHnP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoheshkannan/ML/blob/master/English_to_German_NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnddJQlK6zSb",
        "colab_type": "text"
      },
      "source": [
        "**English to German Neural Machine Translation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8DXfU0Yp8-k",
        "colab_type": "text"
      },
      "source": [
        "1) Data Importing and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_waRgpa0C43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to load the data\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-v1AquI0RHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "document = load_doc('deu-eng.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD6yCKxX0V_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split a document into sentences and make it as source and target using '\\t' as a delimiter\n",
        "def to_pairs(doc):\n",
        "\tlines = doc.strip().split('\\n')\n",
        "\tpairs = [line.split('\\t') for line in  lines]\n",
        "\treturn pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnaGqtN20aON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pairs = to_pairs(document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuMyltyn098q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import re\n",
        "from pickle import dump\n",
        "from unicodedata import normalize\n",
        "from numpy import array\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIh4VBym1Cut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to clean data\n",
        "def clean_pairs(lines):\n",
        "\tcleaned = list()\n",
        "\t# prepare regex for char filtering\n",
        "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor pair in lines:\n",
        "\t\tclean_pair = list()\n",
        "\t\tfor line in pair:\n",
        "\t\t\t# normalize unicode characters\n",
        "\t\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "\t\t\tline = line.decode('UTF-8')\n",
        "\t\t\t# tokenize on white space\n",
        "\t\t\tline = line.split()\n",
        "\t\t\t# convert to lowercase\n",
        "\t\t\tline = [word.lower() for word in line]\n",
        "\t\t\t# remove punctuation from each token\n",
        "\t\t\tline = [word.translate(table) for word in line]\n",
        "\t\t\t# remove non-printable chars form each token\n",
        "\t\t\tline = [re_print.sub('', w) for w in line]\n",
        "\t\t\t# remove tokens with numbers in them\n",
        "\t\t\tline = [word for word in line if word.isalpha()]\n",
        "\t\t\t# store as string\n",
        "\t\t\tclean_pair.append(' '.join(line))\n",
        "\t\tcleaned.append(clean_pair)\n",
        "\treturn array(cleaned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLHCSmPH1dRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_data = clean_pairs(pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-JRrG5_1qeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "7453e664-21b1-4869-e53c-3f51ea0f0a6e"
      },
      "source": [
        "# print first 10 cleaned data\n",
        "for i in range(10):\n",
        "\tprint('[%s] => [%s]' % (clean_data[i,0], clean_data[i,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[go] => [geh]\n",
            "[hi] => [hallo]\n",
            "[hi] => [gru gott]\n",
            "[run] => [lauf]\n",
            "[run] => [lauf]\n",
            "[wow] => [potzdonner]\n",
            "[wow] => [donnerwetter]\n",
            "[fire] => [feuer]\n",
            "[help] => [hilfe]\n",
            "[help] => [zu hulf]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pec8jCCa7Fiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To save our cleaned data in a pickle file\n",
        "def save_clean_data(sentences, filename):\n",
        "\tdump(sentences, open(filename, 'wb'))\n",
        "\tprint('Saved: %s' % filename)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gSt55P_60-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc8c870b-e2f3-42a6-c9bf-7e6178ee57db"
      },
      "source": [
        "save_clean_data(clean_data, 'eng_ger.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: eng_ger.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDDnvI5z7hB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from pickle import dump\n",
        "from numpy.random import rand\n",
        "from numpy.random import shuffle\n",
        "# Function to load pickle file\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiu7FSP18RKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data = load_clean_sentences('eng_ger.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ_MZsZor5rC",
        "colab_type": "text"
      },
      "source": [
        "2) Split data into Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FV5ysEb8h89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e7abb74d-e61f-4ec9-8816-2240ef103e26"
      },
      "source": [
        "import numpy as np\n",
        "# Select number of sentences we need and shuffing it\n",
        "n_sentences = 20000\n",
        "dataset = raw_data[:n_sentences, :]\n",
        "dataset_shuffle = shuffle(dataset)\n",
        "np.round(20000 * 0.8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tuct8nOe9-Ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into train and test set\n",
        "train, test = dataset[:16000], dataset[16000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNvqbJ3b-jE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "d0b19d31-525f-461b-8b54-9d34d182cee0"
      },
      "source": [
        "for i in range(10):\n",
        "\tprint('[%s] => [%s]' % (train[i,0], train[i,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[it was night] => [es war nacht]\n",
            "[im fasting] => [ich faste]\n",
            "[im not yelling] => [ich schreie nicht]\n",
            "[tom moved away] => [tom ist weggezogen]\n",
            "[tom didnt sleep] => [tom hat nicht geschlafen]\n",
            "[is today payday] => [ist heute zahltag]\n",
            "[i feel the same] => [mir geht es genauso]\n",
            "[i hope i win] => [ich hoffe ich gewinne]\n",
            "[i like french] => [ich mag das franzosische]\n",
            "[eat up] => [iss auf]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svc7PpHa-85L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def save_clean_data(sentences, filename):\n",
        "\tdump(sentences, open(filename, 'wb'))\n",
        "\tprint('Saved: %s' % filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsRE0n4X_GEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5501783e-3b17-4522-d85a-12520c101e78"
      },
      "source": [
        "save_clean_data(dataset, 'english-german-both.pkl')\n",
        "save_clean_data(train, 'english-german-train.pkl')\n",
        "save_clean_data(test, 'english-german-test.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: english-german-both.pkl\n",
            "Saved: english-german-train.pkl\n",
            "Saved: english-german-test.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSLKoXOr_J92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = load_clean_sentences('english-german-both.pkl')\n",
        "train = load_clean_sentences('english-german-train.pkl')\n",
        "test = load_clean_sentences('english-german-test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anmn9eaksWZZ",
        "colab_type": "text"
      },
      "source": [
        "3) Prepare Training data.\n",
        "\n",
        "Each input and output must be encoded to integers and padded to the maximum phrase length. This is because we will use the word embeddings to the input sequence and one hot encode the output sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOMegNU2_d5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "#Function to tokenize each word in a sequence\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS8Fl02M_rSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to find out the maximum length of the sequence\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXzOSQ3X_uBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1f27394d-3664-4166-ed5f-d9aceae4ee83"
      },
      "source": [
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 3627\n",
            "English Max Length: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOc_QO2m_zzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1b949167-0f02-4223-9e28-69cc30903083"
      },
      "source": [
        "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
        "ger_length = max_length(dataset[:, 1])\n",
        "print('German Vocabulary Size: %d' % ger_vocab_size)\n",
        "print('German Max Length: %d' % (ger_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "German Vocabulary Size: 5622\n",
            "German Max Length: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIddD5YqBbSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QXYS8C2CLg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to encode sequence and apply padding\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al-3ZS8vDZA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to convert sequences to one hot \n",
        "def encode_output(sequences, vocab_size):\n",
        "\tylist = list()\n",
        "\tfor sequence in sequences:\n",
        "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "\t\tylist.append(encoded)\n",
        "\ty = array(ylist)\n",
        "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "\treturn y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leeWh24QD1Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare training data\n",
        "train_x = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "train_y = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
        "train_y = encode_output(train_y, ger_vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njB7U4amnEvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
        "test_y = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
        "test_y = encode_output(test_y, ger_vocab_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtet8JtXuDdi",
        "colab_type": "text"
      },
      "source": [
        "4) Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XApTODcSrC-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu17WW00rMVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder and Decoder model\n",
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
        "\tmodel.add(LSTM(n_units))\n",
        "\tmodel.add(RepeatVector(tar_timesteps))\n",
        "\tmodel.add(LSTM(n_units, return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41TaHNhJrj5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "fb601fe5-659e-4e84-91ff-77c62a615c15"
      },
      "source": [
        "# define model\n",
        "model = define_model(eng_vocab_size, ger_vocab_size, eng_length, ger_length, 256)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "# summarize defined model\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 5, 256)            928512    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 10, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 10, 256)           525312    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 10, 5622)          1444854   \n",
            "=================================================================\n",
            "Total params: 3,423,990\n",
            "Trainable params: 3,423,990\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5m-99Q-uiUQ",
        "colab_type": "text"
      },
      "source": [
        "5) Fitting a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNklKFWwrmpL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1633d1c5-ba60-4986-f99b-1ed7c5d4d2af"
      },
      "source": [
        "model.fit(train_x, train_y, epochs = 50, batch_size = 64, validation_data=(test_x, test_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 14s 56ms/step - loss: 2.9022 - val_loss: 2.2816\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 2.1950 - val_loss: 2.1585\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 2.0703 - val_loss: 2.0593\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.9490 - val_loss: 1.9525\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.8005 - val_loss: 1.8253\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.6702 - val_loss: 1.7327\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.5639 - val_loss: 1.6598\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.4682 - val_loss: 1.6044\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.3806 - val_loss: 1.5436\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.2958 - val_loss: 1.4884\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.2146 - val_loss: 1.4350\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 1.1354 - val_loss: 1.3939\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 1.0637 - val_loss: 1.3594\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.9938 - val_loss: 1.3247\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.9266 - val_loss: 1.2924\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.8646 - val_loss: 1.2644\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.8071 - val_loss: 1.2458\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.7516 - val_loss: 1.2231\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.7000 - val_loss: 1.2107\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.6522 - val_loss: 1.1934\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.6068 - val_loss: 1.1844\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.5659 - val_loss: 1.1702\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.5274 - val_loss: 1.1625\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 0.4941 - val_loss: 1.1550\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.4617 - val_loss: 1.1541\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.4338 - val_loss: 1.1513\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.4075 - val_loss: 1.1499\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.3839 - val_loss: 1.1525\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.3631 - val_loss: 1.1516\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.3427 - val_loss: 1.1497\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.3249 - val_loss: 1.1520\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.3097 - val_loss: 1.1548\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.2938 - val_loss: 1.1584\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.2816 - val_loss: 1.1664\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.2689 - val_loss: 1.1700\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.2585 - val_loss: 1.1739\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.2476 - val_loss: 1.1787\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 12s 50ms/step - loss: 0.2388 - val_loss: 1.1834\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.2303 - val_loss: 1.1924\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.2235 - val_loss: 1.2005\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.2163 - val_loss: 1.2016\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.2092 - val_loss: 1.2050\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.2030 - val_loss: 1.2138\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.1973 - val_loss: 1.2240\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.1924 - val_loss: 1.2243\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.1878 - val_loss: 1.2353\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.1826 - val_loss: 1.2360\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.1794 - val_loss: 1.2456\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 0.1759 - val_loss: 1.2521\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.1723 - val_loss: 1.2519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f82a01b7fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq5b-Mvcu5Sy",
        "colab_type": "text"
      },
      "source": [
        "6) Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScMueC4Ns9KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for reverse mapping\n",
        "#Model prediction will be a sequence of integers so we can enumerate and look up in the tokenizer to map back to words\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUxixhT6t4u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate target given source sequence\n",
        "def predict_sequence(model, tokenizer, source):\n",
        "\tprediction = model.predict(source, verbose=0)[0]\n",
        "\tintegers = [np.argmax(vector) for vector in prediction]\n",
        "\ttarget = list()\n",
        "\tfor i in integers:\n",
        "\t\tword = word_for_id(i, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\ttarget.append(word)\n",
        "\treturn ' '.join(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4Qu-bO_t8GR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to generate the translated sentences\n",
        "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
        "\tactual, predicted = list(), list()\n",
        "\tfor i, source in enumerate(sources):\n",
        "\t\t# translate encoded source text\n",
        "\t\tsource = source.reshape((1, source.shape[0]))\n",
        "\t\ttranslation = predict_sequence(model, ger_tokenizer, source)\n",
        "\t\traw_src, raw_target = raw_dataset[i]\n",
        "\t\tif i < 10:\n",
        "\t\t  print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
        "\t\tactual.append([raw_target.split()])\n",
        "\t\tpredicted.append(translation.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjUgfwvtuRsb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "678f5555-880c-46ec-a5eb-33a16883e468"
      },
      "source": [
        "evaluate_model(model, ger_tokenizer, test_x, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src=[who hit you], target=[wer hat euch geschlagen], predicted=[wer hat dich geschlagen]\n",
            "src=[now youre safe], target=[jetzt sind sie in sicherheit], predicted=[jetzt bist ihr in sicherheit]\n",
            "src=[everyones going], target=[alle gehen hin], predicted=[alle gehen gerade]\n",
            "src=[i saw the doctor], target=[ich war beim arzt], predicted=[ich habe einen arzt]\n",
            "src=[lets play tag], target=[kommen sie wir spielen jetzt fangen], predicted=[komm wir spielen jetzt fangen]\n",
            "src=[you cant go now], target=[du kannst jetzt nicht weg], predicted=[jetzt kannst jetzt jetzt gehen]\n",
            "src=[who asked you], target=[wer hat dich denn gefragt], predicted=[wer hat dich gefragt]\n",
            "src=[i require advice], target=[ich benotige einen rat], predicted=[ich habe auf diat]\n",
            "src=[start running], target=[fangen sie an zu laufen], predicted=[beginnen sie zu laufen]\n",
            "src=[lets play ball], target=[lasst uns ball spielen], predicted=[lass uns ball spielen]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGtmyT9YwmS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}